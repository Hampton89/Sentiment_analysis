{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asset = pd.read_parquet('Asset_summary_main.parquet')\n",
    "df_news = pd.read_parquet('Quant_news_sentiment.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge news sentiment absolute value from NLP model with asset price "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note, I chose to use abs mean value, because some of the NLP results are extreme negative, or extreme, \n",
    "During a tiemperiod, if the event results are -1, 1, then the direct mean would give 0 sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['Date'] = df_news['Timestamp'].dt.strftime('%Y%m%d')\n",
    "df_news = df_news[(df_news['Timestamp'].dt.hour>=7) & (df_news['Timestamp'].dt.hour<= 11)] \n",
    "df_news[['title_sentiment_i', 'title_sentiment_i']] = df_news[['title_sentiment_i', 'title_sentiment_i']].abs()\n",
    "df_news = df_news.groupby(pd.Grouper(key='Timestamp', freq='1min')).mean().reset_index()\n",
    "\n",
    "df_asset = pd.merge(df_asset, df_news[['Timestamp', 'title_sentiment_i', 'description_sentiment_i']],on='Timestamp', how='left')\n",
    "df_asset[['title_sentiment_i', 'description_sentiment_i']] = df_asset[['title_sentiment_i', 'description_sentiment_i']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_analysis(df_filtered, rolling_period, start_hour = 7, end_hour = 11):\n",
    "    df_filtered['JPY_return'] = np.log(df_asset.JPY_close) - np.log(df_asset.JPY_close.shift(1)) \n",
    "    df_filtered['EUR_return'] = np.log(df_asset.EUR_close) - np.log(df_asset.EUR_close.shift(1)) \n",
    "    df_filtered['TY1_return'] = np.log(df_asset.TY1_close) - np.log(df_asset.TY1_close.shift(1)) \n",
    "    df_filtered['ES1_return'] = np.log(df_asset.ES1_close) - np.log(df_asset.ES1_close.shift(1))\n",
    "\n",
    "    df_filtered['JPY_EUR'] = df_filtered['JPY_return'].rolling(rolling_period).corr(df_filtered['EUR_return']) \n",
    "    df_filtered['JPY_TY1'] = df_filtered['JPY_return'].rolling(rolling_period).corr(df_filtered['TY1_return']) \n",
    "    df_filtered['JPY_SPX'] = df_filtered['JPY_return'].rolling(rolling_period).corr(df_filtered['ES1_return']) \n",
    "    df_filtered['EUR_TY1'] = df_filtered['EUR_return']. rolling(rolling_period). corr(df_filtered['TY1_return']) \n",
    "    df_filtered['EUR_SPX'] = df_filtered['EUR_return'].rolling(rolling_period).corr(df_filtered['ES1_return']) \n",
    "    df_filtered['TY1_SPX'] = df_filtered['TY1_return'].rolling(rolling_period).corr(df_filtered['ES1_return'])\n",
    "\n",
    "    df_filtered = df_filtered[(df_filtered['Timestamp'].dt.hour>=start_hour) & (df_filtered['Timestamp'].dt.hour<= end_hour)] \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Generate dataset according to rolling correlation period\n",
    "For example the default rolling window is 30, which means 30 mins mean & std valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corr = corr_analysis(df_asset, 30, start_hour = 7, end_hour = 11)\n",
    "# df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_corr, x = 'Timestamp', y = ['JPY_EUR', 'JPY_TY1', 'JPY_SPX', 'EUR_TY1', 'EUR_SPX', 'TY1_SPX'])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation reach extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_trade(Pair_selected, upper_corr_tag, lower_corr_tag):\n",
    "    asset_1 = Pair_selected[:3]\n",
    "    asset_2 = Pair_selected[-3:]\n",
    "\n",
    "    for d in df_corr['Date'].unique():\n",
    "        fig,axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "            \n",
    "        data=df_corr[df_corr.Date == d].set_index('Timestamp')\n",
    "        \n",
    "        data['spread_return'] = (data[asset_1+'_return'] - data[asset_2+'_return'])*100 \n",
    "        data['spread_return_accumulated'] = data['spread_return'].cumsum()\n",
    "\n",
    "        # First correlation plot\n",
    "        data[[Pair_selected]].plot(ax=axes[0])\n",
    "        data[['spread_return_accumulated']].plot(secondary_y = True, ax=axes[0]) \n",
    "        axes[0].set_title(f'Correlation_plot_{d}')\n",
    "\n",
    "        # Second asset price plot\n",
    "        data[[asset_1+'_close']].plot(ax=axes[1])\n",
    "        data[[asset_2+'_close']].plot(secondary_y = True, ax=axes[1]) \n",
    "        axes[1].set_title(f'Asset_price_plot_{d}')\n",
    "\n",
    "        # Generate signals\n",
    "        data.loc[data[Pair_selected] > upper_corr_tag, 'Signal'] = -1 # Short signal \n",
    "        data.loc[data[Pair_selected]< lower_corr_tag,'Signal'] = 1 # Long signal \n",
    "        \n",
    "        signals = data['Signal']\n",
    "        green_circles = signals[signals == 1] \n",
    "        red_triangles = signals[signals == -1]\n",
    "\n",
    "        green_index = green_circles.index if len(green_circles.index)!=1 else green_circles.index[0] \n",
    "        red_index = red_triangles.index if len(red_triangles.index)!=1 else red_triangles.index[0] \n",
    "        \n",
    "        # Add signals on plot\n",
    "        axes[0].scatter(green_index, data.loc[green_index, Pair_selected], marker='o', color='green') \n",
    "        axes[0].scatter(red_index, data.loc[red_index, Pair_selected], marker='v', color='red')\n",
    "        \n",
    "        data[['title_sentiment_i', 'description_sentiment_i']].plot(ax=axes[2])\n",
    "        axes[2].set_title(f'News_sentiment_{d}')\n",
    "\n",
    "\n",
    "        fig.tight_layout() \n",
    "        plt.show()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Pair_selected = 'JPY_EUR'\n",
    "# Potential pair selection: 'JPY_EUR', 'JPY_TY1', 'JPY_SPX', 'EUR_TY1', 'EUR_SPX', 'TY1_SPX'\n",
    "upper_corr_tag = -0.1\n",
    "lower_corr_tag = -0.8\n",
    "\n",
    "pair_trade(Pair_selected, upper_corr_tag, lower_corr_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
